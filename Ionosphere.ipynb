{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Ionosphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "0 -0.54487  0.18641 -0.45300      1  \n",
       "1 -0.06288 -0.13738 -0.02447      0  \n",
       "2 -0.24180  0.56045 -0.38238      1  \n",
       "3  1.00000 -0.32382  1.00000      0  \n",
       "4 -0.59573 -0.04608 -0.65697      1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V1     V2     V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
       "0    False  False  False  False  False  False  False  False  False  False   \n",
       "1    False  False  False  False  False  False  False  False  False  False   \n",
       "2    False  False  False  False  False  False  False  False  False  False   \n",
       "3    False  False  False  False  False  False  False  False  False  False   \n",
       "4    False  False  False  False  False  False  False  False  False  False   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "346  False  False  False  False  False  False  False  False  False  False   \n",
       "347  False  False  False  False  False  False  False  False  False  False   \n",
       "348  False  False  False  False  False  False  False  False  False  False   \n",
       "349  False  False  False  False  False  False  False  False  False  False   \n",
       "350  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "     ...    V26    V27    V28    V29    V30    V31    V32    V33    V34  Class  \n",
       "0    ...  False  False  False  False  False  False  False  False  False  False  \n",
       "1    ...  False  False  False  False  False  False  False  False  False  False  \n",
       "2    ...  False  False  False  False  False  False  False  False  False  False  \n",
       "3    ...  False  False  False  False  False  False  False  False  False  False  \n",
       "4    ...  False  False  False  False  False  False  False  False  False  False  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "346  ...  False  False  False  False  False  False  False  False  False  False  \n",
       "347  ...  False  False  False  False  False  False  False  False  False  False  \n",
       "348  ...  False  False  False  False  False  False  False  False  False  False  \n",
       "349  ...  False  False  False  False  False  False  False  False  False  False  \n",
       "350  ...  False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing Data\n",
    "train.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29ff0667a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       0\n",
       "V2       0\n",
       "V3       0\n",
       "V4       0\n",
       "V5       0\n",
       "V6       0\n",
       "V7       0\n",
       "V8       0\n",
       "V9       0\n",
       "V10      0\n",
       "V11      0\n",
       "V12      0\n",
       "V13      0\n",
       "V14      0\n",
       "V15      0\n",
       "V16      0\n",
       "V17      0\n",
       "V18      0\n",
       "V19      0\n",
       "V20      0\n",
       "V21      0\n",
       "V22      0\n",
       "V23      0\n",
       "V24      0\n",
       "V25      0\n",
       "V26      0\n",
       "V27      0\n",
       "V28      0\n",
       "V29      0\n",
       "V30      0\n",
       "V31      0\n",
       "V32      0\n",
       "V33      0\n",
       "V34      0\n",
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems no missing Values in the data\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302034</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>0.156152</td>\n",
       "      <td>0.127606</td>\n",
       "      <td>0.221867</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>0.189242</td>\n",
       "      <td>-0.051883</td>\n",
       "      <td>0.034138</td>\n",
       "      <td>0.072216</td>\n",
       "      <td>0.102558</td>\n",
       "      <td>0.199230</td>\n",
       "      <td>0.113622</td>\n",
       "      <td>0.100474</td>\n",
       "      <td>0.057783</td>\n",
       "      <td>0.076019</td>\n",
       "      <td>0.200237</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>-0.153902</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>-0.082586</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.149789</td>\n",
       "      <td>-0.203100</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>0.133632</td>\n",
       "      <td>-0.121415</td>\n",
       "      <td>0.167031</td>\n",
       "      <td>-0.100914</td>\n",
       "      <td>0.162962</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.465614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.302034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143365</td>\n",
       "      <td>0.476587</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>0.440254</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.471614</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>0.325016</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>0.198306</td>\n",
       "      <td>0.094301</td>\n",
       "      <td>0.221446</td>\n",
       "      <td>0.172002</td>\n",
       "      <td>0.285280</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.149374</td>\n",
       "      <td>0.138065</td>\n",
       "      <td>0.250832</td>\n",
       "      <td>-0.012570</td>\n",
       "      <td>0.304898</td>\n",
       "      <td>-0.073202</td>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.123345</td>\n",
       "      <td>0.344459</td>\n",
       "      <td>0.057890</td>\n",
       "      <td>0.246653</td>\n",
       "      <td>-0.009332</td>\n",
       "      <td>0.263343</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.519145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.006529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>-0.190308</td>\n",
       "      <td>-0.054030</td>\n",
       "      <td>0.255003</td>\n",
       "      <td>-0.302317</td>\n",
       "      <td>0.207697</td>\n",
       "      <td>-0.190090</td>\n",
       "      <td>0.315877</td>\n",
       "      <td>-0.149216</td>\n",
       "      <td>0.236604</td>\n",
       "      <td>-0.253150</td>\n",
       "      <td>0.185872</td>\n",
       "      <td>-0.251143</td>\n",
       "      <td>-0.147451</td>\n",
       "      <td>-0.332213</td>\n",
       "      <td>0.167244</td>\n",
       "      <td>-0.281084</td>\n",
       "      <td>-0.035401</td>\n",
       "      <td>-0.143719</td>\n",
       "      <td>0.164196</td>\n",
       "      <td>-0.104632</td>\n",
       "      <td>-0.236987</td>\n",
       "      <td>-0.046910</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.041090</td>\n",
       "      <td>0.342301</td>\n",
       "      <td>-0.172276</td>\n",
       "      <td>-0.122788</td>\n",
       "      <td>-0.153964</td>\n",
       "      <td>0.034608</td>\n",
       "      <td>0.125884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.156152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476587</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.597075</td>\n",
       "      <td>-0.029794</td>\n",
       "      <td>0.450454</td>\n",
       "      <td>-0.034236</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.042896</td>\n",
       "      <td>0.482118</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>0.398878</td>\n",
       "      <td>0.087992</td>\n",
       "      <td>0.277932</td>\n",
       "      <td>0.027588</td>\n",
       "      <td>0.221532</td>\n",
       "      <td>0.041959</td>\n",
       "      <td>0.326223</td>\n",
       "      <td>0.163663</td>\n",
       "      <td>0.502878</td>\n",
       "      <td>0.098274</td>\n",
       "      <td>0.243063</td>\n",
       "      <td>-0.032254</td>\n",
       "      <td>0.140899</td>\n",
       "      <td>0.184517</td>\n",
       "      <td>0.257646</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>0.383467</td>\n",
       "      <td>-0.099478</td>\n",
       "      <td>0.516477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.127606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>-0.190308</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>-0.120712</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>-0.291447</td>\n",
       "      <td>0.163933</td>\n",
       "      <td>-0.307197</td>\n",
       "      <td>0.135206</td>\n",
       "      <td>-0.359342</td>\n",
       "      <td>0.157740</td>\n",
       "      <td>-0.316705</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>-0.208571</td>\n",
       "      <td>-0.061261</td>\n",
       "      <td>-0.114966</td>\n",
       "      <td>-0.132422</td>\n",
       "      <td>-0.215778</td>\n",
       "      <td>-0.286541</td>\n",
       "      <td>-0.177576</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>-0.175433</td>\n",
       "      <td>-0.068775</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>-0.158090</td>\n",
       "      <td>-0.100240</td>\n",
       "      <td>0.316802</td>\n",
       "      <td>0.016899</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>0.149099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.221867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440254</td>\n",
       "      <td>-0.054030</td>\n",
       "      <td>0.597075</td>\n",
       "      <td>-0.010227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150424</td>\n",
       "      <td>0.461889</td>\n",
       "      <td>-0.090268</td>\n",
       "      <td>0.412876</td>\n",
       "      <td>-0.020395</td>\n",
       "      <td>0.631060</td>\n",
       "      <td>0.083657</td>\n",
       "      <td>0.615407</td>\n",
       "      <td>-0.021493</td>\n",
       "      <td>0.379737</td>\n",
       "      <td>0.115927</td>\n",
       "      <td>0.372572</td>\n",
       "      <td>0.158917</td>\n",
       "      <td>0.586627</td>\n",
       "      <td>0.190805</td>\n",
       "      <td>0.373186</td>\n",
       "      <td>0.112717</td>\n",
       "      <td>0.286749</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>0.109391</td>\n",
       "      <td>0.300632</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.415216</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>-0.076460</td>\n",
       "      <td>0.450429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.027079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.255003</td>\n",
       "      <td>-0.029794</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>-0.150424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.336013</td>\n",
       "      <td>0.373567</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>0.429146</td>\n",
       "      <td>-0.355875</td>\n",
       "      <td>0.253740</td>\n",
       "      <td>-0.352216</td>\n",
       "      <td>0.419673</td>\n",
       "      <td>-0.491863</td>\n",
       "      <td>0.068717</td>\n",
       "      <td>-0.400523</td>\n",
       "      <td>0.077624</td>\n",
       "      <td>-0.370473</td>\n",
       "      <td>-0.212007</td>\n",
       "      <td>-0.270624</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>-0.179928</td>\n",
       "      <td>-0.133023</td>\n",
       "      <td>-0.254130</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>-0.139725</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>-0.166682</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>-0.200860</td>\n",
       "      <td>0.360610</td>\n",
       "      <td>0.207544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.189242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471614</td>\n",
       "      <td>-0.302317</td>\n",
       "      <td>0.450454</td>\n",
       "      <td>-0.120712</td>\n",
       "      <td>0.461889</td>\n",
       "      <td>-0.336013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.251950</td>\n",
       "      <td>0.670813</td>\n",
       "      <td>-0.167705</td>\n",
       "      <td>0.562072</td>\n",
       "      <td>-0.088988</td>\n",
       "      <td>0.618461</td>\n",
       "      <td>-0.032689</td>\n",
       "      <td>0.633574</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>0.067314</td>\n",
       "      <td>0.492411</td>\n",
       "      <td>0.237322</td>\n",
       "      <td>0.352218</td>\n",
       "      <td>0.161258</td>\n",
       "      <td>0.356564</td>\n",
       "      <td>0.107478</td>\n",
       "      <td>0.172210</td>\n",
       "      <td>0.146817</td>\n",
       "      <td>0.329813</td>\n",
       "      <td>-0.031983</td>\n",
       "      <td>0.316021</td>\n",
       "      <td>-0.067499</td>\n",
       "      <td>0.344814</td>\n",
       "      <td>-0.095597</td>\n",
       "      <td>0.294852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>-0.051883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>0.207697</td>\n",
       "      <td>-0.034236</td>\n",
       "      <td>0.200080</td>\n",
       "      <td>-0.090268</td>\n",
       "      <td>0.373567</td>\n",
       "      <td>-0.251950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.337374</td>\n",
       "      <td>0.441505</td>\n",
       "      <td>-0.406358</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>-0.374908</td>\n",
       "      <td>0.334135</td>\n",
       "      <td>-0.392047</td>\n",
       "      <td>0.130752</td>\n",
       "      <td>-0.471665</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>-0.404818</td>\n",
       "      <td>-0.040414</td>\n",
       "      <td>-0.318463</td>\n",
       "      <td>0.101850</td>\n",
       "      <td>-0.254785</td>\n",
       "      <td>-0.043680</td>\n",
       "      <td>-0.250947</td>\n",
       "      <td>0.072018</td>\n",
       "      <td>-0.123296</td>\n",
       "      <td>-0.008578</td>\n",
       "      <td>-0.155661</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>-0.203629</td>\n",
       "      <td>0.098104</td>\n",
       "      <td>0.120634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.034138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.325016</td>\n",
       "      <td>-0.190090</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>-0.291447</td>\n",
       "      <td>0.412876</td>\n",
       "      <td>-0.364003</td>\n",
       "      <td>0.670813</td>\n",
       "      <td>-0.337374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.217968</td>\n",
       "      <td>0.619217</td>\n",
       "      <td>-0.216747</td>\n",
       "      <td>0.664243</td>\n",
       "      <td>-0.031705</td>\n",
       "      <td>0.748290</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>0.590598</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.518041</td>\n",
       "      <td>0.325267</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>0.172768</td>\n",
       "      <td>0.365821</td>\n",
       "      <td>0.131849</td>\n",
       "      <td>0.292281</td>\n",
       "      <td>0.197369</td>\n",
       "      <td>0.396851</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.294646</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>-0.152225</td>\n",
       "      <td>0.167908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.072216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>0.315877</td>\n",
       "      <td>0.042896</td>\n",
       "      <td>0.163933</td>\n",
       "      <td>-0.020395</td>\n",
       "      <td>0.429146</td>\n",
       "      <td>-0.167705</td>\n",
       "      <td>0.441505</td>\n",
       "      <td>-0.217968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.241755</td>\n",
       "      <td>0.422930</td>\n",
       "      <td>-0.232230</td>\n",
       "      <td>0.356078</td>\n",
       "      <td>-0.342053</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>-0.374571</td>\n",
       "      <td>0.143439</td>\n",
       "      <td>-0.287651</td>\n",
       "      <td>-0.038893</td>\n",
       "      <td>-0.360763</td>\n",
       "      <td>0.175459</td>\n",
       "      <td>-0.233369</td>\n",
       "      <td>-0.076828</td>\n",
       "      <td>-0.227890</td>\n",
       "      <td>0.061292</td>\n",
       "      <td>-0.208294</td>\n",
       "      <td>0.138842</td>\n",
       "      <td>-0.208855</td>\n",
       "      <td>0.010276</td>\n",
       "      <td>-0.181166</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>0.159940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.102558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>-0.149216</td>\n",
       "      <td>0.482118</td>\n",
       "      <td>-0.307197</td>\n",
       "      <td>0.631060</td>\n",
       "      <td>-0.355875</td>\n",
       "      <td>0.562072</td>\n",
       "      <td>-0.406358</td>\n",
       "      <td>0.619217</td>\n",
       "      <td>-0.241755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>0.825558</td>\n",
       "      <td>-0.183445</td>\n",
       "      <td>0.676705</td>\n",
       "      <td>-0.015798</td>\n",
       "      <td>0.570487</td>\n",
       "      <td>0.220222</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>0.530798</td>\n",
       "      <td>0.169411</td>\n",
       "      <td>0.364645</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.290095</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.277995</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.355473</td>\n",
       "      <td>-0.041629</td>\n",
       "      <td>0.473780</td>\n",
       "      <td>-0.065131</td>\n",
       "      <td>0.181682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.199230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>0.236604</td>\n",
       "      <td>0.127217</td>\n",
       "      <td>0.135206</td>\n",
       "      <td>0.083657</td>\n",
       "      <td>0.253740</td>\n",
       "      <td>-0.088988</td>\n",
       "      <td>0.323813</td>\n",
       "      <td>-0.216747</td>\n",
       "      <td>0.422930</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.164513</td>\n",
       "      <td>0.188398</td>\n",
       "      <td>-0.296784</td>\n",
       "      <td>0.237243</td>\n",
       "      <td>-0.291325</td>\n",
       "      <td>0.377866</td>\n",
       "      <td>-0.283061</td>\n",
       "      <td>0.199325</td>\n",
       "      <td>-0.315493</td>\n",
       "      <td>0.190690</td>\n",
       "      <td>-0.209360</td>\n",
       "      <td>0.070563</td>\n",
       "      <td>-0.313597</td>\n",
       "      <td>0.066965</td>\n",
       "      <td>-0.215050</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>-0.147949</td>\n",
       "      <td>-0.067790</td>\n",
       "      <td>-0.096091</td>\n",
       "      <td>0.096444</td>\n",
       "      <td>0.197041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.113622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198306</td>\n",
       "      <td>-0.253150</td>\n",
       "      <td>0.398878</td>\n",
       "      <td>-0.359342</td>\n",
       "      <td>0.615407</td>\n",
       "      <td>-0.352216</td>\n",
       "      <td>0.618461</td>\n",
       "      <td>-0.374908</td>\n",
       "      <td>0.664243</td>\n",
       "      <td>-0.232230</td>\n",
       "      <td>0.825558</td>\n",
       "      <td>-0.164513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.136775</td>\n",
       "      <td>0.699406</td>\n",
       "      <td>0.057011</td>\n",
       "      <td>0.669878</td>\n",
       "      <td>0.157237</td>\n",
       "      <td>0.741152</td>\n",
       "      <td>0.257949</td>\n",
       "      <td>0.588450</td>\n",
       "      <td>0.245613</td>\n",
       "      <td>0.456812</td>\n",
       "      <td>0.228787</td>\n",
       "      <td>0.339516</td>\n",
       "      <td>0.164177</td>\n",
       "      <td>0.355917</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.445175</td>\n",
       "      <td>-0.013132</td>\n",
       "      <td>0.490879</td>\n",
       "      <td>-0.119929</td>\n",
       "      <td>0.207201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.100474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094301</td>\n",
       "      <td>0.185872</td>\n",
       "      <td>0.087992</td>\n",
       "      <td>0.157740</td>\n",
       "      <td>-0.021493</td>\n",
       "      <td>0.419673</td>\n",
       "      <td>-0.032689</td>\n",
       "      <td>0.334135</td>\n",
       "      <td>-0.031705</td>\n",
       "      <td>0.356078</td>\n",
       "      <td>-0.183445</td>\n",
       "      <td>0.188398</td>\n",
       "      <td>-0.136775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196752</td>\n",
       "      <td>0.281292</td>\n",
       "      <td>-0.256949</td>\n",
       "      <td>0.329361</td>\n",
       "      <td>-0.273529</td>\n",
       "      <td>0.192689</td>\n",
       "      <td>-0.204735</td>\n",
       "      <td>0.166324</td>\n",
       "      <td>-0.265366</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>-0.313300</td>\n",
       "      <td>0.219421</td>\n",
       "      <td>-0.159639</td>\n",
       "      <td>0.146052</td>\n",
       "      <td>-0.183578</td>\n",
       "      <td>0.101401</td>\n",
       "      <td>-0.179906</td>\n",
       "      <td>0.241702</td>\n",
       "      <td>0.148775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.057783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221446</td>\n",
       "      <td>-0.251143</td>\n",
       "      <td>0.277932</td>\n",
       "      <td>-0.316705</td>\n",
       "      <td>0.379737</td>\n",
       "      <td>-0.491863</td>\n",
       "      <td>0.633574</td>\n",
       "      <td>-0.392047</td>\n",
       "      <td>0.748290</td>\n",
       "      <td>-0.342053</td>\n",
       "      <td>0.676705</td>\n",
       "      <td>-0.296784</td>\n",
       "      <td>0.699406</td>\n",
       "      <td>-0.196752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007889</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>0.659814</td>\n",
       "      <td>0.230555</td>\n",
       "      <td>0.576916</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.554071</td>\n",
       "      <td>0.129545</td>\n",
       "      <td>0.427263</td>\n",
       "      <td>0.168507</td>\n",
       "      <td>0.404276</td>\n",
       "      <td>0.074604</td>\n",
       "      <td>0.358692</td>\n",
       "      <td>0.015888</td>\n",
       "      <td>0.360039</td>\n",
       "      <td>-0.063429</td>\n",
       "      <td>0.087060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.076019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.172002</td>\n",
       "      <td>-0.147451</td>\n",
       "      <td>0.027588</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>0.115927</td>\n",
       "      <td>0.068717</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.130752</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>-0.015798</td>\n",
       "      <td>0.237243</td>\n",
       "      <td>0.057011</td>\n",
       "      <td>0.281292</td>\n",
       "      <td>-0.007889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>0.463448</td>\n",
       "      <td>-0.120252</td>\n",
       "      <td>0.356694</td>\n",
       "      <td>-0.199894</td>\n",
       "      <td>0.184376</td>\n",
       "      <td>-0.175657</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>-0.199799</td>\n",
       "      <td>0.289871</td>\n",
       "      <td>-0.118047</td>\n",
       "      <td>0.067712</td>\n",
       "      <td>-0.158096</td>\n",
       "      <td>0.256970</td>\n",
       "      <td>-0.059076</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.119346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.200237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285280</td>\n",
       "      <td>-0.332213</td>\n",
       "      <td>0.221532</td>\n",
       "      <td>-0.208571</td>\n",
       "      <td>0.372572</td>\n",
       "      <td>-0.400523</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>-0.471665</td>\n",
       "      <td>0.590598</td>\n",
       "      <td>-0.374571</td>\n",
       "      <td>0.570487</td>\n",
       "      <td>-0.291325</td>\n",
       "      <td>0.669878</td>\n",
       "      <td>-0.256949</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043198</td>\n",
       "      <td>0.659809</td>\n",
       "      <td>0.137040</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>0.088268</td>\n",
       "      <td>0.549837</td>\n",
       "      <td>0.173517</td>\n",
       "      <td>0.424692</td>\n",
       "      <td>0.205673</td>\n",
       "      <td>0.473187</td>\n",
       "      <td>0.085579</td>\n",
       "      <td>0.418580</td>\n",
       "      <td>0.124713</td>\n",
       "      <td>0.446093</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.117435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.019230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.167244</td>\n",
       "      <td>0.041959</td>\n",
       "      <td>-0.061261</td>\n",
       "      <td>0.158917</td>\n",
       "      <td>0.077624</td>\n",
       "      <td>0.067314</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.143439</td>\n",
       "      <td>0.220222</td>\n",
       "      <td>0.377866</td>\n",
       "      <td>0.157237</td>\n",
       "      <td>0.329361</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>0.463448</td>\n",
       "      <td>0.043198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058635</td>\n",
       "      <td>0.536966</td>\n",
       "      <td>-0.118455</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>-0.200276</td>\n",
       "      <td>0.397429</td>\n",
       "      <td>-0.165945</td>\n",
       "      <td>0.272236</td>\n",
       "      <td>-0.213057</td>\n",
       "      <td>0.396781</td>\n",
       "      <td>-0.305049</td>\n",
       "      <td>0.125374</td>\n",
       "      <td>-0.107816</td>\n",
       "      <td>0.188940</td>\n",
       "      <td>0.035620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.173828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149374</td>\n",
       "      <td>-0.281084</td>\n",
       "      <td>0.326223</td>\n",
       "      <td>-0.114966</td>\n",
       "      <td>0.586627</td>\n",
       "      <td>-0.370473</td>\n",
       "      <td>0.492411</td>\n",
       "      <td>-0.404818</td>\n",
       "      <td>0.518041</td>\n",
       "      <td>-0.287651</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>-0.283061</td>\n",
       "      <td>0.741152</td>\n",
       "      <td>-0.273529</td>\n",
       "      <td>0.659814</td>\n",
       "      <td>-0.120252</td>\n",
       "      <td>0.659809</td>\n",
       "      <td>-0.058635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025973</td>\n",
       "      <td>0.631976</td>\n",
       "      <td>-0.021007</td>\n",
       "      <td>0.553704</td>\n",
       "      <td>0.160227</td>\n",
       "      <td>0.398951</td>\n",
       "      <td>0.073413</td>\n",
       "      <td>0.479619</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.121923</td>\n",
       "      <td>0.616620</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>0.219583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>-0.153902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138065</td>\n",
       "      <td>-0.035401</td>\n",
       "      <td>0.163663</td>\n",
       "      <td>-0.132422</td>\n",
       "      <td>0.190805</td>\n",
       "      <td>-0.212007</td>\n",
       "      <td>0.237322</td>\n",
       "      <td>-0.040414</td>\n",
       "      <td>0.325267</td>\n",
       "      <td>-0.038893</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>0.199325</td>\n",
       "      <td>0.257949</td>\n",
       "      <td>0.192689</td>\n",
       "      <td>0.230555</td>\n",
       "      <td>0.356694</td>\n",
       "      <td>0.137040</td>\n",
       "      <td>0.536966</td>\n",
       "      <td>-0.025973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162493</td>\n",
       "      <td>0.441735</td>\n",
       "      <td>-0.078714</td>\n",
       "      <td>0.396342</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>0.407093</td>\n",
       "      <td>-0.086614</td>\n",
       "      <td>0.323712</td>\n",
       "      <td>-0.075714</td>\n",
       "      <td>0.207718</td>\n",
       "      <td>-0.090417</td>\n",
       "      <td>0.132848</td>\n",
       "      <td>-0.116385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.011772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250832</td>\n",
       "      <td>-0.143719</td>\n",
       "      <td>0.502878</td>\n",
       "      <td>-0.215778</td>\n",
       "      <td>0.373186</td>\n",
       "      <td>-0.270624</td>\n",
       "      <td>0.352218</td>\n",
       "      <td>-0.318463</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>-0.360763</td>\n",
       "      <td>0.530798</td>\n",
       "      <td>-0.315493</td>\n",
       "      <td>0.588450</td>\n",
       "      <td>-0.204735</td>\n",
       "      <td>0.576916</td>\n",
       "      <td>-0.199894</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>-0.118455</td>\n",
       "      <td>0.631976</td>\n",
       "      <td>0.162493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026267</td>\n",
       "      <td>0.533583</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.569176</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.540443</td>\n",
       "      <td>0.165890</td>\n",
       "      <td>0.538973</td>\n",
       "      <td>0.160531</td>\n",
       "      <td>0.503426</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>0.204361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.082586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012570</td>\n",
       "      <td>0.164196</td>\n",
       "      <td>0.098274</td>\n",
       "      <td>-0.286541</td>\n",
       "      <td>0.112717</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.161258</td>\n",
       "      <td>0.101850</td>\n",
       "      <td>0.172768</td>\n",
       "      <td>0.175459</td>\n",
       "      <td>0.169411</td>\n",
       "      <td>0.190690</td>\n",
       "      <td>0.245613</td>\n",
       "      <td>0.166324</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.184376</td>\n",
       "      <td>0.088268</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>-0.021007</td>\n",
       "      <td>0.441735</td>\n",
       "      <td>-0.026267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>0.352872</td>\n",
       "      <td>-0.036682</td>\n",
       "      <td>0.376951</td>\n",
       "      <td>-0.167937</td>\n",
       "      <td>0.364626</td>\n",
       "      <td>-0.127822</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>-0.211597</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.016717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304898</td>\n",
       "      <td>-0.104632</td>\n",
       "      <td>0.243063</td>\n",
       "      <td>-0.177576</td>\n",
       "      <td>0.286749</td>\n",
       "      <td>-0.179928</td>\n",
       "      <td>0.356564</td>\n",
       "      <td>-0.254785</td>\n",
       "      <td>0.365821</td>\n",
       "      <td>-0.233369</td>\n",
       "      <td>0.364645</td>\n",
       "      <td>-0.209360</td>\n",
       "      <td>0.456812</td>\n",
       "      <td>-0.265366</td>\n",
       "      <td>0.554071</td>\n",
       "      <td>-0.175657</td>\n",
       "      <td>0.549837</td>\n",
       "      <td>-0.200276</td>\n",
       "      <td>0.553704</td>\n",
       "      <td>-0.078714</td>\n",
       "      <td>0.533583</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077006</td>\n",
       "      <td>0.503526</td>\n",
       "      <td>0.176257</td>\n",
       "      <td>0.650908</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.516121</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.111086</td>\n",
       "      <td>0.188185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>0.149789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073202</td>\n",
       "      <td>-0.236987</td>\n",
       "      <td>-0.032254</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>-0.133023</td>\n",
       "      <td>0.107478</td>\n",
       "      <td>-0.043680</td>\n",
       "      <td>0.131849</td>\n",
       "      <td>-0.076828</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.070563</td>\n",
       "      <td>0.228787</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>0.129545</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.173517</td>\n",
       "      <td>0.397429</td>\n",
       "      <td>0.160227</td>\n",
       "      <td>0.396342</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.352872</td>\n",
       "      <td>-0.077006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011314</td>\n",
       "      <td>0.432426</td>\n",
       "      <td>-0.113499</td>\n",
       "      <td>0.281075</td>\n",
       "      <td>-0.162707</td>\n",
       "      <td>0.340692</td>\n",
       "      <td>-0.085966</td>\n",
       "      <td>0.221630</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.203100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077911</td>\n",
       "      <td>-0.046910</td>\n",
       "      <td>0.140899</td>\n",
       "      <td>-0.175433</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>-0.254130</td>\n",
       "      <td>0.172210</td>\n",
       "      <td>-0.250947</td>\n",
       "      <td>0.292281</td>\n",
       "      <td>-0.227890</td>\n",
       "      <td>0.290095</td>\n",
       "      <td>-0.313597</td>\n",
       "      <td>0.339516</td>\n",
       "      <td>-0.313300</td>\n",
       "      <td>0.427263</td>\n",
       "      <td>-0.199799</td>\n",
       "      <td>0.424692</td>\n",
       "      <td>-0.165945</td>\n",
       "      <td>0.398951</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>0.569176</td>\n",
       "      <td>-0.036682</td>\n",
       "      <td>0.503526</td>\n",
       "      <td>-0.011314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.163412</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.160318</td>\n",
       "      <td>0.469326</td>\n",
       "      <td>0.082969</td>\n",
       "      <td>-0.111107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.010725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123345</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.184517</td>\n",
       "      <td>-0.068775</td>\n",
       "      <td>0.109391</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.146817</td>\n",
       "      <td>0.072018</td>\n",
       "      <td>0.197369</td>\n",
       "      <td>0.061292</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.066965</td>\n",
       "      <td>0.164177</td>\n",
       "      <td>0.219421</td>\n",
       "      <td>0.168507</td>\n",
       "      <td>0.289871</td>\n",
       "      <td>0.205673</td>\n",
       "      <td>0.272236</td>\n",
       "      <td>0.073413</td>\n",
       "      <td>0.407093</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.376951</td>\n",
       "      <td>0.176257</td>\n",
       "      <td>0.432426</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042002</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>0.500801</td>\n",
       "      <td>-0.124826</td>\n",
       "      <td>0.376772</td>\n",
       "      <td>0.042756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>0.133632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344459</td>\n",
       "      <td>-0.041090</td>\n",
       "      <td>0.257646</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>0.300632</td>\n",
       "      <td>-0.139725</td>\n",
       "      <td>0.329813</td>\n",
       "      <td>-0.123296</td>\n",
       "      <td>0.396851</td>\n",
       "      <td>-0.208294</td>\n",
       "      <td>0.277995</td>\n",
       "      <td>-0.215050</td>\n",
       "      <td>0.355917</td>\n",
       "      <td>-0.159639</td>\n",
       "      <td>0.404276</td>\n",
       "      <td>-0.118047</td>\n",
       "      <td>0.473187</td>\n",
       "      <td>-0.213057</td>\n",
       "      <td>0.479619</td>\n",
       "      <td>-0.086614</td>\n",
       "      <td>0.540443</td>\n",
       "      <td>-0.167937</td>\n",
       "      <td>0.650908</td>\n",
       "      <td>-0.113499</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.042002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.553855</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.579684</td>\n",
       "      <td>0.082504</td>\n",
       "      <td>0.250036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>-0.121415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057890</td>\n",
       "      <td>0.342301</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.158090</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>-0.031983</td>\n",
       "      <td>-0.008578</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.138842</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.146052</td>\n",
       "      <td>0.074604</td>\n",
       "      <td>0.067712</td>\n",
       "      <td>0.085579</td>\n",
       "      <td>0.396781</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.323712</td>\n",
       "      <td>0.165890</td>\n",
       "      <td>0.364626</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.281075</td>\n",
       "      <td>0.163412</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.163586</td>\n",
       "      <td>0.297085</td>\n",
       "      <td>-0.180566</td>\n",
       "      <td>0.391271</td>\n",
       "      <td>-0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V31</th>\n",
       "      <td>0.167031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246653</td>\n",
       "      <td>-0.172276</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>-0.100240</td>\n",
       "      <td>0.415216</td>\n",
       "      <td>-0.166682</td>\n",
       "      <td>0.316021</td>\n",
       "      <td>-0.155661</td>\n",
       "      <td>0.294646</td>\n",
       "      <td>-0.208855</td>\n",
       "      <td>0.355473</td>\n",
       "      <td>-0.147949</td>\n",
       "      <td>0.445175</td>\n",
       "      <td>-0.183578</td>\n",
       "      <td>0.358692</td>\n",
       "      <td>-0.158096</td>\n",
       "      <td>0.418580</td>\n",
       "      <td>-0.305049</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>-0.075714</td>\n",
       "      <td>0.538973</td>\n",
       "      <td>-0.127822</td>\n",
       "      <td>0.516121</td>\n",
       "      <td>-0.162707</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>0.553855</td>\n",
       "      <td>-0.163586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028877</td>\n",
       "      <td>0.692408</td>\n",
       "      <td>-0.037579</td>\n",
       "      <td>0.294417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V32</th>\n",
       "      <td>-0.100914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009332</td>\n",
       "      <td>-0.122788</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>0.316802</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>-0.067499</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>0.010276</td>\n",
       "      <td>-0.041629</td>\n",
       "      <td>-0.067790</td>\n",
       "      <td>-0.013132</td>\n",
       "      <td>0.101401</td>\n",
       "      <td>0.015888</td>\n",
       "      <td>0.256970</td>\n",
       "      <td>0.124713</td>\n",
       "      <td>0.125374</td>\n",
       "      <td>0.121923</td>\n",
       "      <td>0.207718</td>\n",
       "      <td>0.160531</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.340692</td>\n",
       "      <td>0.160318</td>\n",
       "      <td>0.500801</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.297085</td>\n",
       "      <td>-0.028877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012998</td>\n",
       "      <td>0.514992</td>\n",
       "      <td>-0.036004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V33</th>\n",
       "      <td>0.162962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263343</td>\n",
       "      <td>-0.153964</td>\n",
       "      <td>0.383467</td>\n",
       "      <td>0.016899</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>-0.200860</td>\n",
       "      <td>0.344814</td>\n",
       "      <td>-0.203629</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>-0.181166</td>\n",
       "      <td>0.473780</td>\n",
       "      <td>-0.096091</td>\n",
       "      <td>0.490879</td>\n",
       "      <td>-0.179906</td>\n",
       "      <td>0.360039</td>\n",
       "      <td>-0.059076</td>\n",
       "      <td>0.446093</td>\n",
       "      <td>-0.107816</td>\n",
       "      <td>0.616620</td>\n",
       "      <td>-0.090417</td>\n",
       "      <td>0.503426</td>\n",
       "      <td>-0.211597</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>-0.085966</td>\n",
       "      <td>0.469326</td>\n",
       "      <td>-0.124826</td>\n",
       "      <td>0.579684</td>\n",
       "      <td>-0.180566</td>\n",
       "      <td>0.692408</td>\n",
       "      <td>-0.012998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131840</td>\n",
       "      <td>0.261157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V34</th>\n",
       "      <td>0.010788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.034608</td>\n",
       "      <td>-0.099478</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>-0.076460</td>\n",
       "      <td>0.360610</td>\n",
       "      <td>-0.095597</td>\n",
       "      <td>0.098104</td>\n",
       "      <td>-0.152225</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>-0.065131</td>\n",
       "      <td>0.096444</td>\n",
       "      <td>-0.119929</td>\n",
       "      <td>0.241702</td>\n",
       "      <td>-0.063429</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.188940</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>0.132848</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>0.111086</td>\n",
       "      <td>0.221630</td>\n",
       "      <td>0.082969</td>\n",
       "      <td>0.376772</td>\n",
       "      <td>0.082504</td>\n",
       "      <td>0.391271</td>\n",
       "      <td>-0.037579</td>\n",
       "      <td>0.514992</td>\n",
       "      <td>-0.131840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.465614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519145</td>\n",
       "      <td>0.125884</td>\n",
       "      <td>0.516477</td>\n",
       "      <td>0.149099</td>\n",
       "      <td>0.450429</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.294852</td>\n",
       "      <td>0.120634</td>\n",
       "      <td>0.167908</td>\n",
       "      <td>0.159940</td>\n",
       "      <td>0.181682</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>0.207201</td>\n",
       "      <td>0.148775</td>\n",
       "      <td>0.087060</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.117435</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.219583</td>\n",
       "      <td>-0.116385</td>\n",
       "      <td>0.204361</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.188185</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>-0.111107</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>0.250036</td>\n",
       "      <td>-0.003942</td>\n",
       "      <td>0.294417</td>\n",
       "      <td>-0.036004</td>\n",
       "      <td>0.261157</td>\n",
       "      <td>-0.064168</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1  V2        V3        V4        V5        V6        V7  \\\n",
       "V1     1.000000 NaN  0.302034 -0.006529  0.156152  0.127606  0.221867   \n",
       "V2          NaN NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "V3     0.302034 NaN  1.000000  0.143365  0.476587  0.025768  0.440254   \n",
       "V4    -0.006529 NaN  0.143365  1.000000  0.001152 -0.190308 -0.054030   \n",
       "V5     0.156152 NaN  0.476587  0.001152  1.000000  0.038323  0.597075   \n",
       "V6     0.127606 NaN  0.025768 -0.190308  0.038323  1.000000 -0.010227   \n",
       "V7     0.221867 NaN  0.440254 -0.054030  0.597075 -0.010227  1.000000   \n",
       "V8     0.027079 NaN  0.008717  0.255003 -0.029794  0.274747 -0.150424   \n",
       "V9     0.189242 NaN  0.471614 -0.302317  0.450454 -0.120712  0.461889   \n",
       "V10   -0.051883 NaN  0.047916  0.207697 -0.034236  0.200080 -0.090268   \n",
       "V11    0.034138 NaN  0.325016 -0.190090  0.449829 -0.291447  0.412876   \n",
       "V12    0.072216 NaN  0.169981  0.315877  0.042896  0.163933 -0.020395   \n",
       "V13    0.102558 NaN  0.217597 -0.149216  0.482118 -0.307197  0.631060   \n",
       "V14    0.199230 NaN  0.164550  0.236604  0.127217  0.135206  0.083657   \n",
       "V15    0.113622 NaN  0.198306 -0.253150  0.398878 -0.359342  0.615407   \n",
       "V16    0.100474 NaN  0.094301  0.185872  0.087992  0.157740 -0.021493   \n",
       "V17    0.057783 NaN  0.221446 -0.251143  0.277932 -0.316705  0.379737   \n",
       "V18    0.076019 NaN  0.172002 -0.147451  0.027588  0.188073  0.115927   \n",
       "V19    0.200237 NaN  0.285280 -0.332213  0.221532 -0.208571  0.372572   \n",
       "V20    0.019230 NaN  0.150800  0.167244  0.041959 -0.061261  0.158917   \n",
       "V21    0.173828 NaN  0.149374 -0.281084  0.326223 -0.114966  0.586627   \n",
       "V22   -0.153902 NaN  0.138065 -0.035401  0.163663 -0.132422  0.190805   \n",
       "V23    0.011772 NaN  0.250832 -0.143719  0.502878 -0.215778  0.373186   \n",
       "V24   -0.082586 NaN -0.012570  0.164196  0.098274 -0.286541  0.112717   \n",
       "V25    0.016717 NaN  0.304898 -0.104632  0.243063 -0.177576  0.286749   \n",
       "V26    0.149789 NaN -0.073202 -0.236987 -0.032254  0.041787  0.087734   \n",
       "V27   -0.203100 NaN  0.077911 -0.046910  0.140899 -0.175433  0.097566   \n",
       "V28   -0.010725 NaN  0.123345  0.000743  0.184517 -0.068775  0.109391   \n",
       "V29    0.133632 NaN  0.344459 -0.041090  0.257646 -0.029392  0.300632   \n",
       "V30   -0.121415 NaN  0.057890  0.342301  0.051068 -0.158090 -0.015158   \n",
       "V31    0.167031 NaN  0.246653 -0.172276  0.399840 -0.100240  0.415216   \n",
       "V32   -0.100914 NaN -0.009332 -0.122788  0.025681  0.316802 -0.008323   \n",
       "V33    0.162962 NaN  0.263343 -0.153964  0.383467  0.016899  0.545881   \n",
       "V34    0.010788 NaN  0.000584  0.034608 -0.099478  0.185215 -0.076460   \n",
       "Class  0.465614 NaN  0.519145  0.125884  0.516477  0.149099  0.450429   \n",
       "\n",
       "             V8        V9       V10       V11       V12       V13       V14  \\\n",
       "V1     0.027079  0.189242 -0.051883  0.034138  0.072216  0.102558  0.199230   \n",
       "V2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "V3     0.008717  0.471614  0.047916  0.325016  0.169981  0.217597  0.164550   \n",
       "V4     0.255003 -0.302317  0.207697 -0.190090  0.315877 -0.149216  0.236604   \n",
       "V5    -0.029794  0.450454 -0.034236  0.449829  0.042896  0.482118  0.127217   \n",
       "V6     0.274747 -0.120712  0.200080 -0.291447  0.163933 -0.307197  0.135206   \n",
       "V7    -0.150424  0.461889 -0.090268  0.412876 -0.020395  0.631060  0.083657   \n",
       "V8     1.000000 -0.336013  0.373567 -0.364003  0.429146 -0.355875  0.253740   \n",
       "V9    -0.336013  1.000000 -0.251950  0.670813 -0.167705  0.562072 -0.088988   \n",
       "V10    0.373567 -0.251950  1.000000 -0.337374  0.441505 -0.406358  0.323813   \n",
       "V11   -0.364003  0.670813 -0.337374  1.000000 -0.217968  0.619217 -0.216747   \n",
       "V12    0.429146 -0.167705  0.441505 -0.217968  1.000000 -0.241755  0.422930   \n",
       "V13   -0.355875  0.562072 -0.406358  0.619217 -0.241755  1.000000 -0.092755   \n",
       "V14    0.253740 -0.088988  0.323813 -0.216747  0.422930 -0.092755  1.000000   \n",
       "V15   -0.352216  0.618461 -0.374908  0.664243 -0.232230  0.825558 -0.164513   \n",
       "V16    0.419673 -0.032689  0.334135 -0.031705  0.356078 -0.183445  0.188398   \n",
       "V17   -0.491863  0.633574 -0.392047  0.748290 -0.342053  0.676705 -0.296784   \n",
       "V18    0.068717  0.200786  0.130752  0.107085  0.077798 -0.015798  0.237243   \n",
       "V19   -0.400523  0.673490 -0.471665  0.590598 -0.374571  0.570487 -0.291325   \n",
       "V20    0.077624  0.067314 -0.001418  0.128132  0.143439  0.220222  0.377866   \n",
       "V21   -0.370473  0.492411 -0.404818  0.518041 -0.287651  0.688184 -0.283061   \n",
       "V22   -0.212007  0.237322 -0.040414  0.325267 -0.038893  0.288088  0.199325   \n",
       "V23   -0.270624  0.352218 -0.318463  0.561689 -0.360763  0.530798 -0.315493   \n",
       "V24    0.007045  0.161258  0.101850  0.172768  0.175459  0.169411  0.190690   \n",
       "V25   -0.179928  0.356564 -0.254785  0.365821 -0.233369  0.364645 -0.209360   \n",
       "V26   -0.133023  0.107478 -0.043680  0.131849 -0.076828  0.197266  0.070563   \n",
       "V27   -0.254130  0.172210 -0.250947  0.292281 -0.227890  0.290095 -0.313597   \n",
       "V28    0.072373  0.146817  0.072018  0.197369  0.061292  0.146800  0.066965   \n",
       "V29   -0.139725  0.329813 -0.123296  0.396851 -0.208294  0.277995 -0.215050   \n",
       "V30    0.078585 -0.031983 -0.008578  0.074600  0.138842  0.094400  0.095677   \n",
       "V31   -0.166682  0.316021 -0.155661  0.294646 -0.208855  0.355473 -0.147949   \n",
       "V32    0.152381 -0.067499 -0.015640  0.023922  0.010276 -0.041629 -0.067790   \n",
       "V33   -0.200860  0.344814 -0.203629  0.339506 -0.181166  0.473780 -0.096091   \n",
       "V34    0.360610 -0.095597  0.098104 -0.152225  0.066584 -0.065131  0.096444   \n",
       "Class  0.207544  0.294852  0.120634  0.167908  0.159940  0.181682  0.197041   \n",
       "\n",
       "            V15       V16       V17       V18       V19       V20       V21  \\\n",
       "V1     0.113622  0.100474  0.057783  0.076019  0.200237  0.019230  0.173828   \n",
       "V2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "V3     0.198306  0.094301  0.221446  0.172002  0.285280  0.150800  0.149374   \n",
       "V4    -0.253150  0.185872 -0.251143 -0.147451 -0.332213  0.167244 -0.281084   \n",
       "V5     0.398878  0.087992  0.277932  0.027588  0.221532  0.041959  0.326223   \n",
       "V6    -0.359342  0.157740 -0.316705  0.188073 -0.208571 -0.061261 -0.114966   \n",
       "V7     0.615407 -0.021493  0.379737  0.115927  0.372572  0.158917  0.586627   \n",
       "V8    -0.352216  0.419673 -0.491863  0.068717 -0.400523  0.077624 -0.370473   \n",
       "V9     0.618461 -0.032689  0.633574  0.200786  0.673490  0.067314  0.492411   \n",
       "V10   -0.374908  0.334135 -0.392047  0.130752 -0.471665 -0.001418 -0.404818   \n",
       "V11    0.664243 -0.031705  0.748290  0.107085  0.590598  0.128132  0.518041   \n",
       "V12   -0.232230  0.356078 -0.342053  0.077798 -0.374571  0.143439 -0.287651   \n",
       "V13    0.825558 -0.183445  0.676705 -0.015798  0.570487  0.220222  0.688184   \n",
       "V14   -0.164513  0.188398 -0.296784  0.237243 -0.291325  0.377866 -0.283061   \n",
       "V15    1.000000 -0.136775  0.699406  0.057011  0.669878  0.157237  0.741152   \n",
       "V16   -0.136775  1.000000 -0.196752  0.281292 -0.256949  0.329361 -0.273529   \n",
       "V17    0.699406 -0.196752  1.000000 -0.007889  0.684800  0.035611  0.659814   \n",
       "V18    0.057011  0.281292 -0.007889  1.000000  0.022295  0.463448 -0.120252   \n",
       "V19    0.669878 -0.256949  0.684800  0.022295  1.000000  0.043198  0.659809   \n",
       "V20    0.157237  0.329361  0.035611  0.463448  0.043198  1.000000 -0.058635   \n",
       "V21    0.741152 -0.273529  0.659814 -0.120252  0.659809 -0.058635  1.000000   \n",
       "V22    0.257949  0.192689  0.230555  0.356694  0.137040  0.536966 -0.025973   \n",
       "V23    0.588450 -0.204735  0.576916 -0.199894  0.556622 -0.118455  0.631976   \n",
       "V24    0.245613  0.166324  0.079448  0.184376  0.088268  0.272016 -0.021007   \n",
       "V25    0.456812 -0.265366  0.554071 -0.175657  0.549837 -0.200276  0.553704   \n",
       "V26    0.228787  0.179892  0.129545  0.415094  0.173517  0.397429  0.160227   \n",
       "V27    0.339516 -0.313300  0.427263 -0.199799  0.424692 -0.165945  0.398951   \n",
       "V28    0.164177  0.219421  0.168507  0.289871  0.205673  0.272236  0.073413   \n",
       "V29    0.355917 -0.159639  0.404276 -0.118047  0.473187 -0.213057  0.479619   \n",
       "V30    0.090009  0.146052  0.074604  0.067712  0.085579  0.396781  0.071592   \n",
       "V31    0.445175 -0.183578  0.358692 -0.158096  0.418580 -0.305049  0.511278   \n",
       "V32   -0.013132  0.101401  0.015888  0.256970  0.124713  0.125374  0.121923   \n",
       "V33    0.490879 -0.179906  0.360039 -0.059076  0.446093 -0.107816  0.616620   \n",
       "V34   -0.119929  0.241702 -0.063429  0.054113  0.001458  0.188940 -0.002596   \n",
       "Class  0.207201  0.148775  0.087060  0.119346  0.117435  0.035620  0.219583   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "V1    -0.153902  0.011772 -0.082586  0.016717  0.149789 -0.203100 -0.010725   \n",
       "V2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "V3     0.138065  0.250832 -0.012570  0.304898 -0.073202  0.077911  0.123345   \n",
       "V4    -0.035401 -0.143719  0.164196 -0.104632 -0.236987 -0.046910  0.000743   \n",
       "V5     0.163663  0.502878  0.098274  0.243063 -0.032254  0.140899  0.184517   \n",
       "V6    -0.132422 -0.215778 -0.286541 -0.177576  0.041787 -0.175433 -0.068775   \n",
       "V7     0.190805  0.373186  0.112717  0.286749  0.087734  0.097566  0.109391   \n",
       "V8    -0.212007 -0.270624  0.007045 -0.179928 -0.133023 -0.254130  0.072373   \n",
       "V9     0.237322  0.352218  0.161258  0.356564  0.107478  0.172210  0.146817   \n",
       "V10   -0.040414 -0.318463  0.101850 -0.254785 -0.043680 -0.250947  0.072018   \n",
       "V11    0.325267  0.561689  0.172768  0.365821  0.131849  0.292281  0.197369   \n",
       "V12   -0.038893 -0.360763  0.175459 -0.233369 -0.076828 -0.227890  0.061292   \n",
       "V13    0.288088  0.530798  0.169411  0.364645  0.197266  0.290095  0.146800   \n",
       "V14    0.199325 -0.315493  0.190690 -0.209360  0.070563 -0.313597  0.066965   \n",
       "V15    0.257949  0.588450  0.245613  0.456812  0.228787  0.339516  0.164177   \n",
       "V16    0.192689 -0.204735  0.166324 -0.265366  0.179892 -0.313300  0.219421   \n",
       "V17    0.230555  0.576916  0.079448  0.554071  0.129545  0.427263  0.168507   \n",
       "V18    0.356694 -0.199894  0.184376 -0.175657  0.415094 -0.199799  0.289871   \n",
       "V19    0.137040  0.556622  0.088268  0.549837  0.173517  0.424692  0.205673   \n",
       "V20    0.536966 -0.118455  0.272016 -0.200276  0.397429 -0.165945  0.272236   \n",
       "V21   -0.025973  0.631976 -0.021007  0.553704  0.160227  0.398951  0.073413   \n",
       "V22    1.000000  0.162493  0.441735 -0.078714  0.396342 -0.031281  0.407093   \n",
       "V23    0.162493  1.000000 -0.026267  0.533583  0.051802  0.569176  0.207700   \n",
       "V24    0.441735 -0.026267  1.000000 -0.080108  0.352872 -0.036682  0.376951   \n",
       "V25   -0.078714  0.533583 -0.080108  1.000000 -0.077006  0.503526  0.176257   \n",
       "V26    0.396342  0.051802  0.352872 -0.077006  1.000000 -0.011314  0.432426   \n",
       "V27   -0.031281  0.569176 -0.036682  0.503526 -0.011314  1.000000  0.058253   \n",
       "V28    0.407093  0.207700  0.376951  0.176257  0.432426  0.058253  1.000000   \n",
       "V29   -0.086614  0.540443 -0.167937  0.650908 -0.113499  0.509070  0.042002   \n",
       "V30    0.323712  0.165890  0.364626  0.013639  0.281075  0.163412  0.385475   \n",
       "V31   -0.075714  0.538973 -0.127822  0.516121 -0.162707  0.376400 -0.008136   \n",
       "V32    0.207718  0.160531  0.084291  0.134478  0.340692  0.160318  0.500801   \n",
       "V33   -0.090417  0.503426 -0.211597  0.460692 -0.085966  0.469326 -0.124826   \n",
       "V34    0.132848  0.049284  0.094685  0.111086  0.221630  0.082969  0.376772   \n",
       "Class -0.116385  0.204361  0.006193  0.188185  0.001541 -0.111107  0.042756   \n",
       "\n",
       "            V29       V30       V31       V32       V33       V34     Class  \n",
       "V1     0.133632 -0.121415  0.167031 -0.100914  0.162962  0.010788  0.465614  \n",
       "V2          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "V3     0.344459  0.057890  0.246653 -0.009332  0.263343  0.000584  0.519145  \n",
       "V4    -0.041090  0.342301 -0.172276 -0.122788 -0.153964  0.034608  0.125884  \n",
       "V5     0.257646  0.051068  0.399840  0.025681  0.383467 -0.099478  0.516477  \n",
       "V6    -0.029392 -0.158090 -0.100240  0.316802  0.016899  0.185215  0.149099  \n",
       "V7     0.300632 -0.015158  0.415216 -0.008323  0.545881 -0.076460  0.450429  \n",
       "V8    -0.139725  0.078585 -0.166682  0.152381 -0.200860  0.360610  0.207544  \n",
       "V9     0.329813 -0.031983  0.316021 -0.067499  0.344814 -0.095597  0.294852  \n",
       "V10   -0.123296 -0.008578 -0.155661 -0.015640 -0.203629  0.098104  0.120634  \n",
       "V11    0.396851  0.074600  0.294646  0.023922  0.339506 -0.152225  0.167908  \n",
       "V12   -0.208294  0.138842 -0.208855  0.010276 -0.181166  0.066584  0.159940  \n",
       "V13    0.277995  0.094400  0.355473 -0.041629  0.473780 -0.065131  0.181682  \n",
       "V14   -0.215050  0.095677 -0.147949 -0.067790 -0.096091  0.096444  0.197041  \n",
       "V15    0.355917  0.090009  0.445175 -0.013132  0.490879 -0.119929  0.207201  \n",
       "V16   -0.159639  0.146052 -0.183578  0.101401 -0.179906  0.241702  0.148775  \n",
       "V17    0.404276  0.074604  0.358692  0.015888  0.360039 -0.063429  0.087060  \n",
       "V18   -0.118047  0.067712 -0.158096  0.256970 -0.059076  0.054113  0.119346  \n",
       "V19    0.473187  0.085579  0.418580  0.124713  0.446093  0.001458  0.117435  \n",
       "V20   -0.213057  0.396781 -0.305049  0.125374 -0.107816  0.188940  0.035620  \n",
       "V21    0.479619  0.071592  0.511278  0.121923  0.616620 -0.002596  0.219583  \n",
       "V22   -0.086614  0.323712 -0.075714  0.207718 -0.090417  0.132848 -0.116385  \n",
       "V23    0.540443  0.165890  0.538973  0.160531  0.503426  0.049284  0.204361  \n",
       "V24   -0.167937  0.364626 -0.127822  0.084291 -0.211597  0.094685  0.006193  \n",
       "V25    0.650908  0.013639  0.516121  0.134478  0.460692  0.111086  0.188185  \n",
       "V26   -0.113499  0.281075 -0.162707  0.340692 -0.085966  0.221630  0.001541  \n",
       "V27    0.509070  0.163412  0.376400  0.160318  0.469326  0.082969 -0.111107  \n",
       "V28    0.042002  0.385475 -0.008136  0.500801 -0.124826  0.376772  0.042756  \n",
       "V29    1.000000 -0.011000  0.553855  0.055997  0.579684  0.082504  0.250036  \n",
       "V30   -0.011000  1.000000 -0.163586  0.297085 -0.180566  0.391271 -0.003942  \n",
       "V31    0.553855 -0.163586  1.000000 -0.028877  0.692408 -0.037579  0.294417  \n",
       "V32    0.055997  0.297085 -0.028877  1.000000 -0.012998  0.514992 -0.036004  \n",
       "V33    0.579684 -0.180566  0.692408 -0.012998  1.000000 -0.131840  0.261157  \n",
       "V34    0.082504  0.391271 -0.037579  0.514992 -0.131840  1.000000 -0.064168  \n",
       "Class  0.250036 -0.003942  0.294417 -0.036004  0.261157 -0.064168  1.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='V1',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47357</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.35734</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52879</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V24      V25      V26      V27      V28      V29  \\\n",
       "0  0.03760  ... -0.47357  0.56811 -0.51171  0.41078 -0.46168  0.21266   \n",
       "1 -0.04549  ... -0.35734 -0.20332 -0.26569 -0.20468 -0.18401 -0.19040   \n",
       "2  0.01198  ... -0.12062  0.57528 -0.40220  0.58984 -0.22145  0.43100   \n",
       "3  0.00000  ...  0.00000  1.00000  0.90695  0.51613  1.00000  1.00000   \n",
       "4 -0.16399  ... -0.52879  0.03286 -0.65158  0.13290 -0.53206  0.02431   \n",
       "\n",
       "       V30      V31      V32      V33  \n",
       "0 -0.34090  0.42267 -0.54487  0.18641  \n",
       "1 -0.11593 -0.16626 -0.06288 -0.13738  \n",
       "2 -0.17365  0.60436 -0.24180  0.56045  \n",
       "3 -0.20099  0.25682  1.00000 -0.32382  \n",
       "4 -0.62197 -0.05707 -0.59573 -0.04608  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Feature Selection  \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.iloc[:,0:33]\n",
    "y_train=train.iloc[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.005, random_state=0))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 33\n",
      "selected features: 24\n"
     ]
    }
   ],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "\n",
    "# let's print some stats\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V14', 'V15',\n",
       "       'V18', 'V19', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
       "       'V29', 'V30', 'V31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train[selected_feat]\n",
    "Y=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>-0.44945</td>\n",
       "      <td>0.60536</td>\n",
       "      <td>-0.38542</td>\n",
       "      <td>0.58212</td>\n",
       "      <td>0.56971</td>\n",
       "      <td>-0.29674</td>\n",
       "      <td>0.36946</td>\n",
       "      <td>-0.47357</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>-0.69707</td>\n",
       "      <td>-0.51685</td>\n",
       "      <td>-0.62237</td>\n",
       "      <td>0.33109</td>\n",
       "      <td>-0.13151</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>-0.18056</td>\n",
       "      <td>-0.35734</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>0.54591</td>\n",
       "      <td>-0.13644</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.70887</td>\n",
       "      <td>-0.27502</td>\n",
       "      <td>0.43385</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.39330</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.69975</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>-0.00712</td>\n",
       "      <td>0.34395</td>\n",
       "      <td>-0.21780</td>\n",
       "      <td>0.45107</td>\n",
       "      <td>0.05982</td>\n",
       "      <td>-0.35575</td>\n",
       "      <td>0.02309</td>\n",
       "      <td>-0.52879</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1       V3       V4       V5       V6       V7       V8       V9      V10  \\\n",
       "0   1  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  0.03760   \n",
       "1   1  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000 -0.04549   \n",
       "2   1  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965  0.01198   \n",
       "3   1  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000  0.00000   \n",
       "4   1  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152 -0.16399   \n",
       "\n",
       "       V14      V15      V18      V19      V21      V22      V23      V24  \\\n",
       "0 -0.44945  0.60536 -0.38542  0.58212  0.56971 -0.29674  0.36946 -0.47357   \n",
       "1 -0.69707 -0.51685 -0.62237  0.33109 -0.13151 -0.45300 -0.18056 -0.35734   \n",
       "2  0.00827  0.54591 -0.13644  0.75535  0.70887 -0.27502  0.43385 -0.12062   \n",
       "3  0.00000 -1.00000 -0.39330 -1.00000 -0.69975  1.00000  0.00000  0.00000   \n",
       "4 -0.00712  0.34395 -0.21780  0.45107  0.05982 -0.35575  0.02309 -0.52879   \n",
       "\n",
       "       V25      V26      V27      V28      V29      V30      V31  \n",
       "0  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267  \n",
       "1 -0.20332 -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626  \n",
       "2  0.57528 -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436  \n",
       "3  1.00000  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682  \n",
       "4  0.03286 -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ionosphere\n",
      "Accuracy of Linear SVC classifier on training set: 0.91\n",
      "Accuracy of Linear SVC classifier on test set: 0.89\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "print('Ionosphere')\n",
    "print('Accuracy of Linear SVC classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Linear SVC classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " [[ 2.00982232  0.38384394  0.06554786  0.0296088   0.52078341  0.53307273\n",
      "   0.25848122  0.47481426  0.39819442  0.1977865   0.4003861   0.25509441\n",
      "  -0.29781332 -0.21835615 -1.01798421  0.53257699  0.31499975  0.04485433\n",
      "  -0.15747306 -1.10532282 -0.09300861  0.71730493  0.44281611  0.2082702 ]]\n",
      "Intercepts:\n",
      " [-2.54820451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf1 = LinearSVC(C=5, random_state = 67).fit(X_train, y_train)\n",
    "print('Coefficients:\\n', clf1.coef_)\n",
    "print('Intercepts:\\n', clf1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', C=10).fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_poly=SVC(kernel='poly', C=100,probability=True).fit(X_train, y_train)\n",
    "svm_poly.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7840909090909091"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_sigmoid=SVC(kernel='sigmoid', C=100,probability=True).fit(X_train, y_train)\n",
    "svm_sigmoid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886363636363636"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_decf = SVC(kernel='rbf', C=1,decision_function_shape='ovr').fit(X_train, y_train)\n",
    "svm_decf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.736, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.811, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.736, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.788, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.788, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.660, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.942, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.792, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.811, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.885, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.943, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.830, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.942, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.887, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.811, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.849, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.846, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.846, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.660, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.673, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.943, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.887, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.887, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.943, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.885, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.849, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.849, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.885, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.811, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.849, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.846, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.846, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.943, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.887, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.942, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.885, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.981, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.904, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.849, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.925, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.904, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.811, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.868, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.906, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.865, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.865, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_decf = SVC(kernel='rbf', C=10,decision_function_shape='ovr').fit(X_train, y_train)\n",
    "svm_decf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886363636363636"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_decf = SVC(kernel='rbf', C=1,decision_function_shape='ovr').fit(X_train, y_train)\n",
    "svm_decf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        38\n",
      "           1       1.00      0.92      0.96        50\n",
      "\n",
      "    accuracy                           0.95        88\n",
      "   macro avg       0.95      0.96      0.95        88\n",
      "weighted avg       0.96      0.95      0.95        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "grid_predictions = grid.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Decision Tree \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0.02374105 0.06210046 0.018268   0.41060649 0.01508451 0.\n",
      " 0.06504191 0.         0.01560017 0.03096627 0.         0.\n",
      " 0.         0.         0.         0.01722024 0.01523844 0.02644232\n",
      " 0.         0.28830487 0.         0.         0.01138528 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('Feature importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 8}\n",
      "Best score is 0.9002414486921528\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,Y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659090909090909"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.90\n",
      "Accuracy of Logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 0)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF classifier on training set: 1.00\n",
      "Accuracy of RF classifier on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 0)\n",
    "\n",
    "clf = RandomForestClassifier(max_features = 12, random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF classifier on training set: 1.00\n",
      "Accuracy of RF classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 0)\n",
    "\n",
    "clf = RandomForestClassifier(max_features=3,random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=12)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(criterion='entropy', max_features=12)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent class \n",
      " [[37  1]\n",
      " [ 1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predicted=clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test,predicted)\n",
    "\n",
    "print ('Most frequent class \\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
